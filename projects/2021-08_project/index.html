<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ananya  Nandy | Measuring dimensions of product similarity</title>
    <meta name="author" content="Ananya  Nandy" />
    <meta name="description" content="research" />
    <meta name="keywords" content="design, engineering" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/face-logo.png"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ananyan.github.io/projects/2021-08_project/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://ananyan.github.io/"><span class="font-weight-bold">Ananya</span>   Nandy</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/assets/pdf/AnanyaNandy_CV_0125.pdf">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Measuring dimensions of product similarity</h1>
            <p class="post-description">research</p>
          </header>

          <article>
            <h2 id="overview"><u>Overview</u></h2>
<p><strong>My Role:</strong> Lead researcher <br>
<strong>Tools/Skills:</strong> Network Analysis, Survey Design, Triplet Embedding, Semantic Embedding, Image Classification, Statistical Analysis, MATLAB, Python <br>
<strong>Timeline:</strong> August 2019 - August 2021, May 2023 - August 2024 (3.25 years)<br>
<strong>Team:</strong> N/A</p>

<h2 id="context"><u>Context</u></h2>
<p>Similarity is a fundamental concept that helps humans make sense of the world around them, ranging from recognizing and categorizing objects, to conducting more complex tasks like analogical reasoning. Therefore, the way humans internally represent similarity can influence how they structure their ideas, knowledge, and even decisions. Aside from relevance to cognition, capturing similarity is crucial for enabling large-scale search, informational retrieval, recommendation, or decision-support systems. For example, e-commerce websites try to recommend products that are similar to ones consumers have searched for and music streaming applications try to enhance playlists by adding similar songs. Quantifying similarity in the right way is challenging, but critical, for a multitude of applications, one of which is supporting creativity and ideation during early-stage design. In this context, similarity can be considered from functional, visual, and semantic perspectives. Functional similarity can help designers transfer knowledge about the purpose and mechanism of a system into an innovative solution to a new problem. Visual and semantic similarity are relevant in enabling designers to convey the meaning of a product, in comparison to other products and the external environment, to users.</p>

<h2 id="goal"><u>Goal</u></h2>
<ul>
  <li>Evaluate different similarity measures, including mathematical approaches and human-centered approaches, and how they impact product retrieval at a functional level</li>
  <li>Understand how product similarity can be conveyed at a visual and semantic level</li>
  <li>Establish an understanding of how similarity plays a role in product design, providing guidelines for the development and use of similarity measures for relevant contexts and application</li>
</ul>

<h2 id="outcomes"><u>Outcomes</u></h2>
<p>1) Analyzed 100 products (ranging in complexity from systems like wind turbines to household appliances to toys) for their similarity in function using 6 different mathematical measures across 2 different mathematical representations (vectors and graphs)</p>

<p>2) Designed surveys to collect over 1000 triplet ratings (“Is A more similar to B or to C?”) that considered variable dimensions of product similarity (Are the products similar in their purpose or in how they work?). Used the triplets to train low-dimensional embeddings from the triplet ratings to obtain measures of human-perceived functional similarity between products</p>

<p>3) Determined that graph-based measures could <em>better</em> capture human-perceived similarity across the variable dimensions, but that general-purpose measures and human perceptions were misaligned</p>

<p>4) Analyzed the semantic similarity of abstract words to describe products (“A chair that is <em>dependable</em>” or “A chair that is <em>friendly</em>) utilizing semantic embeddings from Transformer models</p>

<p>5) Discovered, through image classification, that semantic similarity of the above prompts were reflected visually in the products (decreased semantic similarity was associated with increased ability for a machine to distinguish the images perceptually)</p>

<div class="row">
    <div class="w-75 p-3" style="margin:auto">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/DesignSim/semanticandvisualsim-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/DesignSim/semanticandvisualsim-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/DesignSim/semanticandvisualsim-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/DesignSim/semanticandvisualsim.png" alt="Figure that shows process of extracting image features and using support vector machine classification with semantic labels">

  </picture>

</figure>

    </div>
</div>

<h2 id="key-insights-and-impact"><u>Key Insights and Impact</u></h2>
<h4 id="1-product-similarity-along-the-functional-dimension"><strong>1. Product similarity along the functional dimension</strong></h4>
<p>Perceptions of what products are considered functionally similar are complicated by framing, with humans considering similarity at various levels of abstraction. The dynamic nature of humans’ structuring of the similarity space makes it particularly challenging to quantify functional similarity using static measures on static product representations, due to misalignment with humans’ internal representations. Depending on what is important for the context (e.g., capturing low-level features of the product function vs. a higher-level functional goal), the choice of similarity measure may need to change. Therefore, creativity support systems such as those for analogical reasoning must be flexible in their similarity representations, perhaps adapting measures or quantification based on inference of a user’s intent.</p>

<div class="row">
    <div class="w-75 p-3" style="margin:auto">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/DesignSim/analogicalreasoning-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/DesignSim/analogicalreasoning-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/DesignSim/analogicalreasoning-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid" src="/assets/img/DesignSim/analogicalreasoning.png" alt="Figure that shows process of extracting functional analogies using abstract schema and products that are near (e.g., chairs and chairs) vs. far (e.g., chairs and toys)">

  </picture>

</figure>

    </div>
</div>

<h4 id="2-product-similarity-along-the-semantic-dimension"><strong>2. Product similarity along the semantic dimension</strong></h4>
<p>Semantic representations of products (e.g., product descriptions) contain rich information about product including its function and form. Machine learning (ML) models can encode humans’ representations of language, enabling their use for establishing a semantic space of product similarity. When the semantic representation is more abstract, referring to high-level, conceptual descriptions of a product (e.g., <em>luxurious</em>, <em>sporty</em>), this information is built into humans’ internal representations of the key words. While state-of-the-art ML models can capture these more abstract concepts to an extent, they cannot necessarily make the subtle distinctions connecting these concepts to specific classes of products, particularly new types of products, without additional training. Therefore, new methods may need to be developed to utilize semantic similarity for product design (e.g., methods for breaking abstract words down into more concrete and interpretable formats for natural language systems).</p>

<h4 id="3-product-similarity-along-the-visual-dimension"><strong>3. Product similarity along the visual dimension</strong></h4>
<p>Visual similarity can be captured using image or geometric 3D representations of the products. Products that have relatively similar function may or may not be visually similar. For instance, consider the concept of a “hands-free smart phone,” which can be functionally implemented in many ways, including smart glasses (e.g., Google Glass or Ray-Ban Meta Smart Glasses), which will be visually similar to each other, or a visually dissimilar wearable (e.g., Humane AI Pin). With improvements in multi-model AI, it is increasingly possible to use pixel-level representations, but capture semantic (or perhaps functional) meaning. At the same time, it is important to note that in product design, it may be important to capture only visual similarity across far domains (e.g., silhouettes for bio-inspired design) to enable inspiration for a product’s form or aesthetic.</p>

<p><strong>These insights can be applied to the development of creativity support tools, specifically those meant for product design. In particular, this work demonstrates the various dimensions of similarity that need to be considered for design-related cognition and decision making, as well as how they can be operationalized computationally.</strong></p>

<h2 id="reflection"><u>Reflection</u></h2>
<p>This research was heavily focused on quantifying similarity in a product design context. Additional research would need to be done, but ideally, the result would be a complete set of dimensions that are important to consider when assessing product similarity, ways to measure those dimensions, and evaluation of the degree to which measures align with human perceptions. I think such an outcome could help developers operationalize similarity in ways that take advantage of what we know about human cognition and the design process, making computational tools that are useful for designers. Since similarity is dynamic and multi-dimensional, there doesn’t appear to be a one-size-fits-all approach to quantifying similarity that can capture the wide variety of tasks that designers face in their work. However, embedding tools with flexibility to adapt to how humans think, across abstraction and different dimensions, could enable computational systems to more seamlessly help with the types of complex tasks typical of design.</p>

<p>See the following publications for more details about these projects:<br>
<a href="https://ananyan.github.io/assets/pdf/nandy-2020-jmd.pdf">Evaluating Quantitative Measures for Assessing Functional Similarity in Engineering Design (Journal of Mechanical Design 2022)</a><br>
<a href="https://ananyan.github.io/assets/pdf/nandy-2021-jmd.pdf">Do human and computational evaluations of similarity align? An empirical study of product function (Journal of Mechanical Design 2022)</a><br>
<a href="https://ananyan.github.io/assets/pdf/nandy-semanticprompts-dcc.pdf">Semantic properties of word prompts shape design outcomes: understanding the influence of semantic richness and similarity (Design Computing and Cognition 2024)</a></p>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Ananya  Nandy. Using <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

